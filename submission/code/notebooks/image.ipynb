{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "helpful-adams",
   "metadata": {},
   "source": [
    "# CNN Image Sentiment Analysis\n",
    "Code to train a CNN image classifier.\n",
    "\n",
    "Note that the final version of this code was run on the server as my computer was not powerful enough, and hence the latest version of my image classifier is found in server_code/classify_image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "approved-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import utils.data\n",
    "import utils.model\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-evaluation",
   "metadata": {},
   "source": [
    "Set out the parameters of this training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supposed-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of ravdess, ravdess-faces, fer+\n",
    "dataset = \"fer+\"\n",
    "FOUR_EMOTIONS = False\n",
    "\n",
    "# One of RN50\n",
    "EXPERIMENT = \"RN50\"\n",
    "\n",
    "DIMS = (197,197)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-uganda",
   "metadata": {},
   "source": [
    "We use transfer learning, on top of the ResNet CNN, using frames extracted from our videos to get the specific model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT in ['RN18-FER+', 'RN18-MS']:\n",
    "    channels_first = True\n",
    "else:\n",
    "    channels_first = False\n",
    "    \n",
    "trainX, valX, testX, trainY, valY, testY, lb = utils.data.load_img_dataset(dataset, channels_first, FOUR_EMOTIONS, dims=DIMS)\n",
    "\n",
    "print(trainX.shape)\n",
    "\n",
    "# Randomly change the train set so results are more generalizable\n",
    "if EXPERIMENT in ['RN18-FER+', 'RN18-MS']:\n",
    "    data_format = 'channels_first'\n",
    "    train_augmentation = ImageDataGenerator(\n",
    "        fill_mode=\"nearest\",\n",
    "        data_format=data_format)\n",
    "else:\n",
    "    data_format = 'channels_last'\n",
    "    train_augmentation = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        data_format=data_format)\n",
    "\n",
    "val_augmentation = ImageDataGenerator(data_format=data_format)\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "train_augmentation.mean = mean\n",
    "val_augmentation.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "secure-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return utils.model.get_model(EXPERIMENT, len(lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-policy",
   "metadata": {},
   "source": [
    "Set up the training procedure, using stochastic gradient descent. In the server version of this code we use a more complicated training procedure, where we first train the last few layers of the network, and then continue to train the whole network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loose-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "\n",
    "def train():\n",
    "    # default hyperparameters\n",
    "    config_defaults = {\n",
    "        'batch_size' : 32,\n",
    "        'learning_rate' : 0.0008475,\n",
    "        'epochs': 30,\n",
    "        'momentum' : 0.9,\n",
    "        'decay': 1e-4\n",
    "    }\n",
    "\n",
    "    wandb.init(project='sentiment', config=config_defaults)\n",
    "    config = wandb.config\n",
    "    \n",
    "    config.architecture_name = EXPERIMENT\n",
    "    config.dataset = dataset\n",
    "    \n",
    "    # Compile the model, using stochastic gradient descent optimization.\n",
    "    opt = SGD(lr=config.learning_rate, momentum=config.momentum, decay=config.decay / config.epochs)\n",
    "    model = get_model()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "    # Now we can start training!\n",
    "    H = model.fit(\n",
    "        x = trainX,\n",
    "        y = trainY,\n",
    "        batch_size=config.batch_size,\n",
    "        steps_per_epoch = len(trainX) // config.batch_size,\n",
    "        validation_data = (valX, valY),\n",
    "        validation_steps = len(valX) // config.batch_size,\n",
    "        epochs = config.epochs,\n",
    "        callbacks = [WandbCallback()]\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-tuition",
   "metadata": {},
   "source": [
    "Next, we setup a sweep of hyperparameters, using Bayesian optimization, implemented by weights and biases (wandb.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-essay",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_loss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "        \"epochs\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"min\": 20,\n",
    "            \"max\": 40\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"min\": 30,\n",
    "            \"max\": 64\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.001\n",
    "        },\n",
    "        \"momentum\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.9,\n",
    "            \"max\": 0.99\n",
    "        },\n",
    "        \"decay\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 1e-6,\n",
    "            \"max\": 1e-2\n",
    "        }\n",
    "    },\n",
    "    \"early_terminate\" :\n",
    "    {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 3\n",
    "    }\n",
    "}\n",
    "\n",
    "wandb.sweep(sweep_config, project='sentiment')\n",
    "wandb.agent(sweep_id, project='sentiment', function=train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
