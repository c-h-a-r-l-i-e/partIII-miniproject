{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "industrial-diesel",
   "metadata": {},
   "source": [
    "# CNN Video Sentiment Analysis\n",
    "This notebook will walk through the process of training a CNN to analyse frames of videos, and then take the aggregate over frames in a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guided-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import utils.data\n",
    "import utils.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "applied-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcharlieisalright\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "piano-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of ravdess, ravdess-faces\n",
    "dataset = \"fer+\"\n",
    "\n",
    "# One of RN18-FER+, RN18-MS, or RN50\n",
    "EXPERIMENT = \"RN18-FER+\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-indian",
   "metadata": {},
   "source": [
    "We use transfer learning, on top of the ResNet CNN, using frames extracted from our videos to get the specific model. In this case, we are training using data at 720p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "streaming-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT in ['RN18-FER+', 'RN18-MS']:\n",
    "    channels_first = True\n",
    "else:\n",
    "    channels_first = False\n",
    "    \n",
    "trainX, valX, testX, trainY, valY, testY, lb = utils.data.load_img_dataset(dataset, channels_first)\n",
    "\n",
    "\n",
    "# Randomly change the train set so results are more generalizable\n",
    "if EXPERIMENT in ['RN18-FER+', 'RN18-MS']:\n",
    "    data_format = 'channels_first'\n",
    "    train_augmentation = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        data_format=data_format)\n",
    "else:\n",
    "    data_format = 'channels_last'\n",
    "    train_augmentation = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        data_format=data_format)\n",
    "\n",
    "val_augmentation = ImageDataGenerator(data_format=data_format)\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "train_augmentation.mean = mean\n",
    "val_augmentation.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "catholic-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25238\n"
     ]
    }
   ],
   "source": [
    "print(len(trainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "previous-commodity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25238\n"
     ]
    }
   ],
   "source": [
    "print(len(trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "traditional-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return utils.model.get_model(EXPERIMENT, len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atlantic-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # default hyperparameters\n",
    "    config_defaults = {\n",
    "        'batch_size' : 31,\n",
    "        'learning_rate' : 0.0008475,\n",
    "        'epochs': 49,\n",
    "        'momentum' : 0.9,\n",
    "        'decay': 1e-4\n",
    "    }\n",
    "\n",
    "    wandb.init(project='sentiment', entity='charlieisalright', config=config_defaults)\n",
    "    config = wandb.config\n",
    "    \n",
    "    config.architecture_name = EXPERIMENT\n",
    "    config.dataset = dataset\n",
    "    \n",
    "    # Compile the model, using stochastic gradient descent optimization.\n",
    "    opt = SGD(lr=config.learning_rate, momentum=config.momentum, decay=config.decay / config.epochs)\n",
    "    model = get_model()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "    # Now we can start training!\n",
    "    H = model.fit(\n",
    "        x = train_augmentation.flow(trainX, trainY, batch_size=config.batch_size),\n",
    "        steps_per_epoch = len(trainX) // config.batch_size,\n",
    "        validation_data = val_augmentation.flow(valX, valY),\n",
    "        validation_steps = len(valX) // config.batch_size,\n",
    "        epochs = config.epochs,\n",
    "        callbacks = [WandbCallback()]\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-redhead",
   "metadata": {},
   "source": [
    "Next, we setup a sweep of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/Documents/courses/miniproject/env/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">morning-planet-232</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/charlieisalright/sentiment\" target=\"_blank\">https://wandb.ai/charlieisalright/sentiment</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/charlieisalright/sentiment/runs/cf5z4hhi\" target=\"_blank\">https://wandb.ai/charlieisalright/sentiment/runs/cf5z4hhi</a><br/>\n",
       "                Run data is saved locally in <code>/home/charlie/Documents/courses/miniproject/notebooks/wandb/run-20210419_165915-cf5z4hhi</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/Documents/courses/miniproject/env/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py:1028: UserWarning: onnx2keras.pooling_layers is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  warnings.warn('{} is not loaded, but a Lambda layer uses it. '\n"
     ]
    }
   ],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_loss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "        \"epochs\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"min\": 13,\n",
    "            \"max\": 50\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"min\": 4,\n",
    "            \"max\": 64\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.01\n",
    "        }\n",
    "    }\n",
    "}\n",
    "sweep_id = 'ocuhuuax' #wandb.sweep(sweep_config, project='sentiment')\n",
    "wandb.agent(sweep_id, project='sentiment', function=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-peninsula",
   "metadata": {},
   "source": [
    "Finally, evaluate the network, and plot some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"../models/best-models/resnet50-face.h5\")\n",
    "\n",
    "predictions = model.predict(x=testX.astype(\"float32\"), batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "matrix = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1), normalize='true')\n",
    "\n",
    "plt.imshow(matrix, interpolation=\"nearest\")\n",
    "\n",
    "target_names = lb.classes_\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "\n",
    "thresh = matrix.max() / 1.5\n",
    "for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "    plt.text(j, i, \"{:0.2f}\".format(matrix[i, j]),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if matrix[i, j] < thresh else \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-invasion",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "This works but provides accuracy of only about 0.3 ish. Next thing to try is using a face details model first!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "\n",
    "model.save(\"../models/best-models/resnet50-direct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "if PLOT:\n",
    "    from tensorflow import keras\n",
    "    keras.utils.plot_model(get_RN50_model(), show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    model = get_model()\n",
    "    model.predict(np.array(data[0:2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
